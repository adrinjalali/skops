import tempfile
from functools import cache
from pathlib import Path

import numpy as np
import pytest
from scipy import special
from sklearn.base import BaseEstimator
from sklearn.datasets import load_breast_cancer, load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import make_scorer
from sklearn.model_selection import GridSearchCV
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import FeatureUnion, Pipeline
from sklearn.preprocessing import (
    FunctionTransformer,
    MinMaxScaler,
    PolynomialFeatures,
    StandardScaler,
)

from skops._persist import load, save


@cache
def clf_data():
    X, y = load_iris(return_X_y=True, as_frame=False)
    return X, y


@cache
def regr_data():
    X, y = load_breast_cancer(return_X_y=True, as_frame=False)
    return X, y


class TestGeneral:
    @pytest.fixture(scope="class")
    def temp_path(self):
        with tempfile.TemporaryDirectory(prefix="skops-test-temp-path") as temp_path:
            yield Path(temp_path)

    @pytest.mark.xfail(strict=True)
    def test_passing_file_handler(self, temp_path):
        filename = temp_path / "a-file.zip"
        with open(filename, "w") as f:
            save("hello world", f)
        with open(filename, "r") as f:
            loaded = load(f)
        assert loaded == "hello world"

    def test_unfitted_estimator(self, temp_path):
        # also works with unfitted estimators
        X, y = clf_data()
        estimator = LogisticRegression(random_state=0, solver="liblinear")
        filename = temp_path / "model.zip"
        save(estimator, filename)
        loaded = load(filename)

        assert loaded.get_params(deep=True) == estimator.get_params(deep=True)
        loaded.fit(X, y)  # does not raise

    @pytest.mark.xfail(strict=True)
    def test_adding_custom_methods(self):
        # yet to be implmeneted
        assert False


def assert_params_equal(params0, params1):
    # helper function to compare estimator params
    assert len(params0) == len(params1)
    assert set(params0.keys()) == set(params1.keys())
    for key in params0:
        if key.endswith("steps") or key.endswith("transformer_list"):
            # TODO: anything smarter?
            continue

        val0, val1 = params0[key], params1[key]
        assert type(val0) == type(val1)
        if isinstance(val0, BaseEstimator):
            assert_params_equal(val0.get_params(), val1.get_params())
        elif isinstance(val0, (np.ndarray, np.generic)):
            np.testing.assert_allclose(val0, val1)
        else:
            assert val0 == val1


class EstimatorBaseTester:
    @pytest.fixture(scope="class")
    def data(self):
        # implement the data used to train and test this estimator
        raise NotImplementedError

    @pytest.fixture(scope="class")
    def estimator(self, data):
        # implement the estimator to be tested
        raise NotImplementedError

    def test_get_output(self, estimator, loaded, data):
        # check that the output generated by the estimator is as expected
        raise NotImplementedError

    def test_partial_fit(self, estimator, loaded, data):
        # overwrite this if the estimator can be partial_fitted after loading
        pytest.skip("This estimator does not support partial_fit")

    @pytest.fixture(scope="class")
    def temp_path(self):
        with tempfile.TemporaryDirectory(prefix="skops-test-temp-path") as temp_path:
            yield Path(temp_path)

    @pytest.fixture(scope="class")
    def loaded(self, estimator, temp_path):
        filename = temp_path / "model.zip"
        save(estimator, filename)
        loaded = load(filename)
        return loaded

    def test_type(self, estimator, loaded):
        assert type(estimator) == type(loaded)

    def test_get_params(self, estimator, loaded):
        # first check if estimator even has get_params
        if not hasattr(estimator, "get_params"):
            assert not hasattr(loaded, "get_params")
            return

        params_original = estimator.get_params(deep=True)
        params_loaded = loaded.get_params(deep=True)
        assert_params_equal(params_original, params_loaded)

    def test_learned_attributes(estimator, loaded):
        for attr in dir(estimator):
            # only check attributes that end on "_"
            if attr.startswith("_") or not attr.endswith("_"):
                continue

            attr_before = getattr(estimator, attr)
            attr_after = getattr(loaded, attr)

            if isinstance(attr_before, (np.ndarray, np.generic)):
                np.testing.assert_allclose(attr_before, attr_after)
            else:
                assert attr_before == attr_after


class TestStandardScaler(EstimatorBaseTester):
    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        X, _ = data
        return StandardScaler().fit(X)

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.transform(X)
        X_loaded = loaded.transform(X)
        np.testing.assert_allclose(X_original, X_loaded)


class TestLogisticRegression(EstimatorBaseTester):
    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        X, y = data
        return LogisticRegression(random_state=0, solver="liblinear").fit(X, y)

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.predict_proba(X)
        X_loaded = loaded.predict_proba(X)
        np.testing.assert_allclose(X_original, X_loaded)


@pytest.mark.xfail(strict=True)
class TestMlpRegressor(EstimatorBaseTester):
    # Fails as RandomState cannot yet be saved
    @pytest.fixture(scope="class")
    def data(self):
        return regr_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        X, y = data
        return MLPRegressor(random_state=0).fit(X, y)

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.predict_proba(X)
        X_loaded = loaded.predict_proba(X)
        np.testing.assert_allclose(X_original, X_loaded)

    def test_partial_fit(self, estimator, loaded, data):
        # continue training and check that outputs are identical afterwads
        X, y = data
        estimator.partial_fit(X, y)
        loaded.partial_fit(X, y)
        self.test_get_output(estimator, loaded, data)


class TestClfPipeline(EstimatorBaseTester):
    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        X, y = data
        pipeline = Pipeline(
            [
                ("scaler", StandardScaler()),
                ("clf", LogisticRegression(random_state=0, solver="liblinear")),
            ]
        )
        return pipeline.fit(X, y)

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.predict_proba(X)
        X_loaded = loaded.predict_proba(X)
        np.testing.assert_allclose(X_original, X_loaded)


class TestFeatureUnion(EstimatorBaseTester):
    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        X, y = data
        union = FeatureUnion(
            [
                ("scaler", StandardScaler()),
                ("poly", PolynomialFeatures()),
            ]
        )
        return union.fit(X, y)

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.transform(X)
        X_loaded = loaded.transform(X)
        np.testing.assert_allclose(X_original, X_loaded)


class TestClfPipelineAndFeatureUnion(EstimatorBaseTester):
    """More complex, nested feature union + pipeline"""

    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        X, y = data
        # fmt: off
        pipeline = Pipeline([
            ("features", FeatureUnion([
                ("scaler", StandardScaler()),
                ("scaled-poly", Pipeline([
                    ("polys", FeatureUnion([
                        ("poly1", PolynomialFeatures()),
                        ("poly2", PolynomialFeatures(degree=3, include_bias=False))
                    ])),
                    ("scale", MinMaxScaler()),
                ])),
            ])),
            ("clf", LogisticRegression(random_state=0, solver="liblinear")),
        ])
        # fmt: on
        return pipeline.fit(X, y)

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.predict_proba(X)
        X_loaded = loaded.predict_proba(X)
        np.testing.assert_allclose(X_original, X_loaded)


class TestFunctionTransformerNumpy(EstimatorBaseTester):
    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        return FunctionTransformer(
            func=np.sqrt,
            inverse_func=np.square,
        )

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.transform(X)
        X_loaded = loaded.transform(X)
        np.testing.assert_allclose(X_original, X_loaded)

        X_original_inv = estimator.inverse_transform(X_original)
        X_loaded_inv = estimator.inverse_transform(X_loaded)
        np.testing.assert_allclose(X_original_inv, X_loaded_inv)
        np.testing.assert_allclose(X_loaded_inv, X)


@pytest.mark.xfail(strict=True)
class TestFunctionTransformerScipy(EstimatorBaseTester):
    # scipy ufuncs look as if they belonged to numpy, thus fail
    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        return FunctionTransformer(
            func=special.erf,
            inverse_func=special.erfinv,
        )

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.transform(X)
        X_loaded = loaded.transform(X)
        np.testing.assert_allclose(X_original, X_loaded)

        X_original_inv = estimator.inverse_transform(X_original)
        X_loaded_inv = estimator.inverse_transform(X_loaded)
        np.testing.assert_allclose(X_original_inv, X_loaded_inv)
        np.testing.assert_allclose(X_loaded_inv, X)


@pytest.mark.xfail(strict=True)
class TestScorer(EstimatorBaseTester):
    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        return make_scorer("accuracy")

    def test_get_output(self, estimator, loaded, data):
        _, y = data
        y_pred = y[::-1]
        score_original = estimator(y, y_pred)
        score_loaded = estimator(y, y_pred)
        assert score_original == score_loaded


@pytest.mark.xfail(strict=True)
class TestGridSearchCV(EstimatorBaseTester):
    @pytest.fixture(scope="class")
    def data(self):
        return clf_data()

    @pytest.fixture(scope="class")
    def estimator(self, data):
        X, y = data
        params = {"clf__C": [0.1, 1.0], "scaler": [StandardScaler(), MinMaxScaler()]}
        pipeline = Pipeline(
            [
                ("scaler", StandardScaler()),
                ("clf", LogisticRegression(random_state=0, solver="liblinear")),
            ]
        )
        search = GridSearchCV(pipeline, params)
        return search.fit(X, y)

    def test_get_output(self, estimator, loaded, data):
        X, _ = data
        X_original = estimator.predict_proba(X)
        X_loaded = loaded.predict_proba(X)
        np.testing.assert_allclose(X_original, X_loaded)
